{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJEA3Ap62BI7hQMCy7ubOe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Pythonで学ぶ画像認識　第5章 画像分類\n","##第5.2節 データセットの準備"],"metadata":{"id":"DjLIh1ZEV3UD"}},{"cell_type":"markdown","source":["###モジュールのインポート"],"metadata":{"id":"jKbIqBVPWpR-"}},{"cell_type":"code","source":["import random\n","import numpy as np\n","from PIL import Image\n","from typing import Sequence, Callable\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as T\n","import torchvision.transforms.functional as F"],"metadata":{"id":"aFpcGXs2WrZa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###物体検出用COCOデータセットを扱うCocoDetectionクラス"],"metadata":{"id":"IFSVkl3o8sQS"}},{"cell_type":"code","source":["class CocoDetection(torchvision.datasets.CocoDetection):\n","    '''\n","    物体検出用COCOデータセット読み込みクラス\n","    img_directory: 画像ファイルが保存されてるディレクトリへのパス\n","    anno_file    : アノテーションファイルのパス\n","    transform    : データ拡張と整形を行うクラスインスタンス\n","    '''\n","    def __init__(self, img_directory: str, anno_file: str,\n","                 transform: Callable=None):\n","        super().__init__(img_directory, anno_file)\n","\n","        self.transform = transform\n","\n","        # カテゴリーIDに欠番があるため、それを埋めてクラスIDを割り当て\n","        self.classes = []\n","        # 元々のクラスIDと新しく割り当てたクラスIDを相互に変換する\n","        # ためのマッピングを保持\n","        self.coco_to_pred = {}\n","        self.pred_to_coco = {}\n","        for i, category_id in enumerate(\n","                sorted(self.coco.cats.keys())):\n","            self.classes.append(self.coco.cats[category_id]['name'])\n","            self.coco_to_pred[category_id] = i\n","            self.pred_to_coco[i] = category_id\n","\n","    '''\n","    データ取得関数\n","    idx: サンプルを指すインデックス\n","    '''\n","    def __getitem__(self, idx: int):\n","        img, target = super().__getitem__(idx)\n","\n","        # 親クラスのコンストラクタでself.idsに画像IDが\n","        # 格納されているのでそれを取得\n","        img_id = self.ids[idx]\n","\n","        # 物体の集合を一つの矩形でアノテーションしているものを除外\n","        target = [obj for obj in target\n","                  if 'iscrowd' not in obj or obj['iscrowd'] == 0]\n","\n","        # 学習用に当該画像に映る物体のクラスIDと矩形を取得\n","        # クラスIDはコンストラクタで新規に割り当てたIDに変換\n","        classes = torch.tensor([self.coco_to_pred[obj['category_id']]\n","                                for obj in target], dtype=torch.int64)\n","        boxes = torch.tensor([obj['bbox'] for obj in target],\n","                             dtype=torch.float32)\n","\n","        # 矩形が0個のとき、boxes.shape == [0]となってしまうため、\n","        # 第1軸に4を追加して軸数と第2軸の次元を合わせる\n","        if boxes.shape[0] == 0:\n","            boxes = torch.zeros((0, 4))\n","\n","        width, height = img.size\n","        # xmin, ymin, width, height -> xmin, ymin, xmax, ymax\n","        boxes[:, 2:] += boxes[:, :2]\n","\n","        # 矩形が画像領域内に収まるように値をクリップ\n","        boxes[:, ::2] = boxes[:, ::2].clamp(min=0, max=width)\n","        boxes[:, 1::2] = boxes[:, 1::2].clamp(min=0, max=height)\n","\n","        # 学習のための正解データを用意\n","        # クラスIDや矩形など渡すものが多岐にわたるため、辞書で用意\n","        target = {\n","            'image_id': torch.tensor(img_id, dtype=torch.int64),\n","            'classes': classes,\n","            'boxes': boxes,\n","            'size': torch.tensor((width, height), dtype=torch.int64),\n","            'orig_size': torch.tensor((width, height),\n","                                      dtype=torch.int64),\n","            'orig_img': torch.tensor(np.asarray(img))\n","        }\n","\n","        # データ拡張と整形\n","        if self.transform is not None:\n","            img, target = self.transform(img, target)\n","\n","        return img, target\n","\n","    '''\n","    モデルで予測されたクラスIDからCOCOのクラスIDに変換する関数\n","    label: 予測されたクラスID\n","    '''\n","    def to_coco_label(self, label: int):\n","        return self.pred_to_coco[label]"],"metadata":{"id":"L7q0Ov4T8x2E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###無作為に画像を水平反転するクラス"],"metadata":{"id":"ZrXXSpiJ-2I2"}},{"cell_type":"code","source":["class RandomHorizontalFlip:\n","    '''\n","    無作為に画像を水平反転するクラス\n","    prob: 水平反転する確率\n","    '''\n","    def __init__(self, prob: float=0.5):\n","        self.prob = prob\n","\n","    '''\n","    無作為に画像を水平反転する関数\n","    img   : 水平反転する画像\n","    target: 物体検出用のラベルを持つ辞書\n","    '''\n","    def __call__(self, img: Image, target: dict):\n","        if random.random() < self.prob:\n","            # 画像の水平反転\n","            img = F.hflip(img)\n","\n","            # 正解矩形をx軸方向に反転\n","            # xmin, xmaxは水平反転すると大小が逆転し、\n","            # width - xmax, width - xminとなる\n","            width = img.size[0]\n","            target['boxes'][:, [0, 2]] = width - \\\n","                target['boxes'][:, [2, 0]]\n","\n","        return img, target"],"metadata":{"id":"LNwH1Ztw-5ym"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###無作為に画像を切り抜くクラス"],"metadata":{"id":"36KyArnm_rMw"}},{"cell_type":"code","source":["class RandomSizeCrop:\n","    '''\n","    無作為に画像を切り抜くクラス\n","    scale: 切り抜き前に対する切り抜き後の画像面積の下限と上限\n","    ratio: 切り抜き後の画像のアスペクト比の下限と上限\n","    '''\n","    def __init__(self, scale: Sequence[float],\n","                 ratio: Sequence[float]):\n","        self.scale = scale\n","        self.ratio = ratio\n","\n","    '''\n","    無作為に画像を切り抜く関数\n","    img   : 切り抜きをする画像\n","    target: 物体検出用のラベルを持つ辞書\n","    '''\n","    def __call__(self, img: Image, target: dict):\n","        width, height = img.size\n","\n","        # 切り抜く領域の左上の座標と幅および高さを取得\n","        # 切り抜く領域はscaleとratioの下限と上限に従う\n","        top, left, cropped_height, cropped_width = \\\n","            T.RandomResizedCrop.get_params(\n","                img, self.scale, self.ratio)\n","\n","        # 左上の座標と幅および高さで指定した領域を切り抜き\n","        img = F.crop(img, top, left, cropped_height, cropped_width)\n","\n","        # 原点がx = left, y = topに移動し、合わせて矩形の座標も移動\n","        target['boxes'][:, ::2] -= left\n","        target['boxes'][:, 1::2] -= top\n","\n","        # 矩形の座標が切り抜き後に領域外に出る場合は座標をクリップ\n","        target['boxes'][:, ::2] = \\\n","            target['boxes'][:, ::2].clamp(min=0)\n","        target['boxes'][:, 1::2] = \\\n","            target['boxes'][:, 1::2].clamp(min=0)\n","        target['boxes'][:, ::2] = \\\n","            target['boxes'][:, ::2].clamp(max=cropped_width)\n","        target['boxes'][:, 1::2] = \\\n","            target['boxes'][:, 1::2].clamp(max=cropped_height)\n","\n","        # 幅と高さが0より大きくなる(矩形の面積が0でない)矩形のみ保持\n","        keep = (target['boxes'][:, 2] > target['boxes'][:, 0]) & \\\n","            (target['boxes'][:, 3] > target['boxes'][:, 1])\n","        target['classes'] = target['classes'][keep]\n","        target['boxes'] = target['boxes'][keep]\n","\n","        # 切り抜き後の画像の大きさを保持\n","        target['size'] = torch.tensor(\n","            [cropped_width, cropped_height], dtype=torch.int64)\n","\n","        return img, target"],"metadata":{"id":"TKYc2IUr_ulN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###無作為に画像をリサイズするクラス"],"metadata":{"id":"EcyzJYyuAwHf"}},{"cell_type":"code","source":["class RandomResize:\n","    '''\n","    無作為に画像をアスペクト比を保持してリサイズするクラス\n","    min_sizes: 短辺の長さの候補、この中から無作為に長さを抽出\n","    max_size :  長辺の長さの最大値\n","    '''\n","    def __init__(self, min_sizes: Sequence[int], max_size: int):\n","        self.min_sizes = min_sizes\n","        self.max_size = max_size\n","\n","    '''\n","    リサイズ後の短辺と長辺を計算する関数\n","    min_side: 短辺の長さ\n","    max_side: 長辺の長さ\n","    target  : 目標となる短辺の長さ\n","    '''\n","    def _get_target_size(self, min_side: int, max_side:int,\n","                         target: int):\n","        # アスペクト比を保持して短辺をtargetに合わせる\n","        max_side = int(max_side * target / min_side)\n","        min_side = target\n","\n","        # 長辺がmax_sizeを超えている場合、\n","        # アスペクト比を保持して長辺をmax_sizeに合わせる\n","        if max_side > self.max_size:\n","            min_side = int(min_side * self.max_size / max_side)\n","            max_side = self.max_size\n","\n","        return min_side, max_side\n","\n","    '''\n","    無作為に画像をリサイズする関数\n","    img   : リサイズする画像\n","    target: 物体検出用のラベルを持つ辞書\n","    '''\n","    def __call__(self, img: Image, target: dict):\n","        # 短辺の長さを候補の中から無作為に抽出\n","        min_size = random.choice(self.min_sizes)\n","\n","        width, height = img.size\n","\n","        # リサイズ後の大きさを取得\n","        # 幅と高さのどちらが短辺であるかで場合分け\n","        if width < height:\n","            resized_width, resized_height = self._get_target_size(\n","                width, height, min_size)\n","        else:\n","            resized_height, resized_width = self._get_target_size(\n","                height, width, min_size)\n","\n","        # 指定した大きさに画像をリサイズ\n","        img = F.resize(img, (resized_height, resized_width))\n","\n","        # 正解矩形をリサイズ前後のスケールに合わせて変更\n","        ratio = resized_width / width\n","        target['boxes'] *= ratio\n","\n","        # リサイズ後の画像の大きさを保持\n","        target['size'] = torch.tensor(\n","            [resized_width, resized_height], dtype=torch.int64)\n","\n","        return img, target"],"metadata":{"id":"R8NnhNStAwP9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###PIL画像をテンソルに変換するクラス"],"metadata":{"id":"lO8NX061BvQu"}},{"cell_type":"code","source":["class ToTensor:\n","    '''\n","    PIL画像をテンソルに変換する関数\n","    img   : テンソルに変換する画像\n","    target: 物体検出用のラベルを持つ辞書\n","    '''\n","    def __call__(self, img: Image, target: dict):\n","        img = F.to_tensor(img)\n","\n","        return img, target"],"metadata":{"id":"RTqRQrXXByPR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###画像を標準化するクラス"],"metadata":{"id":"w-EAGmbbCEpJ"}},{"cell_type":"code","source":["class Normalize:\n","    '''\n","    画像を標準化するクラス\n","    mean: R, G, Bチャネルそれぞれの平均値\n","    std : R, G, Bチャネルそれぞれの標準偏差\n","    '''\n","    def __init__(self, mean: Sequence[float], std: Sequence[float]):\n","        self.mean = mean\n","        self.std = std\n","\n","    '''\n","    画像を標準化する関数\n","    img   : 標準化する画像\n","    target: 物体検出用のラベルを持つ辞書\n","    '''\n","    def __call__(self, img: torch.Tensor, target: dict):\n","        img = F.normalize(img, mean=self.mean, std=self.std)\n","\n","        return img, target"],"metadata":{"id":"rfHi21e9CG3a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###データ整形・拡張をまとめるクラス"],"metadata":{"id":"8JdeTcxyCycQ"}},{"cell_type":"code","source":["class Compose:\n","    '''\n","    データ整形・拡張をまとめて適用するためのクラス\n","    transforms: データ整形・拡張のクラスインスタンスのシーケンス\n","    '''\n","    def __init__(self, transforms: Sequence[Callable]):\n","        self.transforms = transforms\n","\n","    '''\n","    データ整形・拡張を連続して適用する関数\n","    img   : データ整形・拡張する画像\n","    target: 物体検出用のラベルを持つ辞書\n","    '''\n","    def __call__(self, img: Image, target: dict):\n","        for transform in self.transforms:\n","            img, target = transform(img, target)\n","\n","        return img, target"],"metadata":{"id":"DirPK2mNC2K-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2つのデータ拡張から無作為にどちらかを選択して適用する関数"],"metadata":{"id":"UTy9XBvxD0Av"}},{"cell_type":"code","source":["class RandomSelect:\n","    '''\n","    2種類のデータ拡張を受け取り、無作為にどちらかを適用するクラス\n","    transform1: データ拡張1\n","    transform2: データ拡張2\n","    prob      : データ拡張1が適用される確率\n","    '''\n","    def __init__(self, transform1: Callable, transform2: Callable,\n","                 prob: float=0.5):\n","        self.transform1 = transform1\n","        self.transform2 = transform2\n","        self.prob = prob\n","\n","    '''\n","    データ拡張を無作為に選択して適用する関数\n","    img   : データ整形・拡張する画像\n","    target: 物体検出用のラベルを持つ辞書\n","    '''\n","    def __call__(self, img: Image, target: dict):\n","        if random.random() < self.prob:\n","            return self.transform1(img, target)\n","\n","        return self.transform2(img, target)"],"metadata":{"id":"i5APzNHuD0k1"},"execution_count":null,"outputs":[]}]}